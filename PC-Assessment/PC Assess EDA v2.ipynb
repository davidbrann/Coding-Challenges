{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8326dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8f4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30275f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appetency\n",
       "-1    49110\n",
       " 1      890\n",
       "Name: appetency, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('orange_small_train_appetency.labels')\n",
    "\n",
    "labels.groupby('appetency')['appetency'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227cdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  For the small dataset, the first 190 variables are numerical and the last 40 are categorical\n",
    "df = pd.read_csv('orange_small_train.data.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68315623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var183</th>\n",
       "      <th>Var184</th>\n",
       "      <th>Var185</th>\n",
       "      <th>Var186</th>\n",
       "      <th>Var187</th>\n",
       "      <th>Var188</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var190</th>\n",
       "      <th>Var209</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>702.000000</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>1.487000e+03</td>\n",
       "      <td>44471.000000</td>\n",
       "      <td>44461.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>1.487000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.241000e+03</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>702.00000</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>21022.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.487179</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>425.298387</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>2.387933e+05</td>\n",
       "      <td>1326.437116</td>\n",
       "      <td>6.809496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.145299</td>\n",
       "      <td>3.926057e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.777380e+04</td>\n",
       "      <td>8.460919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.299145</td>\n",
       "      <td>16.54416</td>\n",
       "      <td>167.368477</td>\n",
       "      <td>270.142137</td>\n",
       "      <td>22007.045192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.709951</td>\n",
       "      <td>0.141933</td>\n",
       "      <td>4270.193518</td>\n",
       "      <td>1.275481</td>\n",
       "      <td>6.441259e+05</td>\n",
       "      <td>2685.693668</td>\n",
       "      <td>6.326053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.777855</td>\n",
       "      <td>9.280896e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016188e+05</td>\n",
       "      <td>46.973777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.781967</td>\n",
       "      <td>60.22303</td>\n",
       "      <td>113.980072</td>\n",
       "      <td>86.707692</td>\n",
       "      <td>29085.146490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-6.420000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>19.380000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>2732.670000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>197.640000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>12668.940000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187425e+05</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.628630e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.881000e+04</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>252.960000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>29396.340000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>680.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>130668.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>6.048550e+06</td>\n",
       "      <td>131761.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>1.232559e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.048400e+06</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>910.00000</td>\n",
       "      <td>628.620000</td>\n",
       "      <td>642.000000</td>\n",
       "      <td>230427.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Var1         Var2           Var3         Var4          Var5  \\\n",
       "count  702.000000  1241.000000    1240.000000  1579.000000  1.487000e+03   \n",
       "mean    11.487179     0.004029     425.298387     0.125396  2.387933e+05   \n",
       "std     40.709951     0.141933    4270.193518     1.275481  6.441259e+05   \n",
       "min      0.000000     0.000000       0.000000     0.000000  0.000000e+00   \n",
       "25%      0.000000     0.000000       0.000000     0.000000  0.000000e+00   \n",
       "50%      0.000000     0.000000       0.000000     0.000000  0.000000e+00   \n",
       "75%     16.000000     0.000000       0.000000     0.000000  1.187425e+05   \n",
       "max    680.000000     5.000000  130668.000000    27.000000  6.048550e+06   \n",
       "\n",
       "                Var6          Var7  Var8         Var9         Var10  ...  \\\n",
       "count   44471.000000  44461.000000   0.0   702.000000  1.487000e+03  ...   \n",
       "mean     1326.437116      6.809496   NaN    48.145299  3.926057e+05  ...   \n",
       "std      2685.693668      6.326053   NaN   154.777855  9.280896e+05  ...   \n",
       "min         0.000000      0.000000   NaN     0.000000  0.000000e+00  ...   \n",
       "25%       518.000000      0.000000   NaN     4.000000  0.000000e+00  ...   \n",
       "50%       861.000000      7.000000   NaN    20.000000  0.000000e+00  ...   \n",
       "75%      1428.000000      7.000000   NaN    46.000000  2.628630e+05  ...   \n",
       "max    131761.000000    140.000000   NaN  2300.000000  1.232559e+07  ...   \n",
       "\n",
       "             Var183       Var184  Var185      Var186     Var187       Var188  \\\n",
       "count  1.241000e+03  1241.000000     0.0  702.000000  702.00000  1241.000000   \n",
       "mean   7.777380e+04     8.460919     NaN    3.299145   16.54416   167.368477   \n",
       "std    2.016188e+05    46.973777     NaN    8.781967   60.22303   113.980072   \n",
       "min    0.000000e+00     0.000000     NaN    0.000000    0.00000    -6.420000   \n",
       "25%    0.000000e+00     0.000000     NaN    0.000000    0.00000    19.380000   \n",
       "50%    0.000000e+00     0.000000     NaN    0.000000    4.00000   197.640000   \n",
       "75%    4.881000e+04     8.000000     NaN    6.000000   14.00000   252.960000   \n",
       "max    3.048400e+06  1200.000000     NaN  102.000000  910.00000   628.620000   \n",
       "\n",
       "             Var189         Var190  Var209  Var230  \n",
       "count  21022.000000     333.000000     0.0     0.0  \n",
       "mean     270.142137   22007.045192     NaN     NaN  \n",
       "std       86.707692   29085.146490     NaN     NaN  \n",
       "min        6.000000       0.000000     NaN     NaN  \n",
       "25%      204.000000    2732.670000     NaN     NaN  \n",
       "50%      270.000000   12668.940000     NaN     NaN  \n",
       "75%      330.000000   29396.340000     NaN     NaN  \n",
       "max      642.000000  230427.000000     NaN     NaN  \n",
       "\n",
       "[8 rows x 192 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafac653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our labels with the data and away we go! \n",
    "df2 = pd.concat([df.reset_index(drop=True), labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d914242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.Var229.value_counts().plot(kind=\"bar\",\n",
    "#                            title=\"VarXXX\",\n",
    "#                            rot=15,\n",
    "#                            xlabel=\"VarXXX\",\n",
    "#                            ylabel=\"Count\")\n",
    "\n",
    "# df2[df2['appetency'] == -1].Var221.value_counts().plot(kind=\"pie\", title=\"Var227\")\n",
    "\n",
    "# df2[df2['appetency'] == 1].Var221.value_counts().plot(kind=\"pie\", title=\"Var227\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c55352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Some fun with paired pie charts \n",
    "\n",
    "# for varNum in range(208,231):\n",
    "#     varName = \"Var\" + str(varNum)\n",
    "    \n",
    "#     valuesP = df2.loc[df2['appetency'] == 1, varName].value_counts()\n",
    "#     labelsP = df2.loc[df2['appetency'] == 1, varName].unique().tolist()\n",
    "\n",
    "#     valuesN = df2.loc[df2['appetency'] == -1, varName].value_counts()\n",
    "#     labelsN = df2.loc[df2['appetency'] == -1, varName].unique().tolist()\n",
    "    \n",
    "#     if(len(labelsN) <= 20):\n",
    "#         fig = make_subplots(rows=1, cols=2, specs = [[{'type':'domain'},{'type':'domain'}]])\n",
    "\n",
    "#         fig.add_trace(go.Pie(labels = labelsP, values = valuesP, name = 'Positive'), 1, 1)\n",
    "#         fig.add_trace(go.Pie(labels = labelsN, values = valuesN, name = 'Negative'), 1, 2)\n",
    "\n",
    "#         # use 'hole' to create a donut-like pie chart\n",
    "#         fig.update_traces(hole = 0.4, hoverinfo = 'label+percent+name')\n",
    "\n",
    "#         fig.update_layout(title_text = varName, annotations = [dict(text='Positive', x=0.18, y = 0.5, font_size=20,showarrow=False),\n",
    "#                                                                dict(text='Negative', x=0.82, y = 0.5, font_size=20,showarrow=False)])\n",
    "#         fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07449084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at missing values\n",
    "\n",
    "dfPos = df2.loc[df2['appetency'] == 1]\n",
    "dfNeg = df2.loc[df2['appetency'] == -1]\n",
    "\n",
    "dfPosMiss = dfPos.isnull().sum()\n",
    "dfNegMiss = dfNeg.isnull().sum()\n",
    "\n",
    "allMiss =  pd.concat([dfPosMiss, dfNegMiss], axis=1)\n",
    "\n",
    "allMiss.columns = ['PosMissCount', 'NegMissCount']\n",
    "\n",
    "\n",
    "allMiss['PosMissPerc'] = allMiss.PosMissCount / 890\n",
    "allMiss['NegMissPerc'] = allMiss.NegMissCount / 49110\n",
    "\n",
    "\n",
    "allMiss['PosNegDiff'] = allMiss.PosMissPerc - allMiss.NegMissPerc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffc750bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var6', 'Var7', 'Var13', 'Var21', 'Var22', 'Var24', 'Var25', 'Var28',\n",
       "       'Var35', 'Var38', 'Var44', 'Var65', 'Var72', 'Var74', 'Var76', 'Var78',\n",
       "       'Var81', 'Var83', 'Var85', 'Var94', 'Var109', 'Var112', 'Var119',\n",
       "       'Var123', 'Var125', 'Var126', 'Var132', 'Var133', 'Var134', 'Var140',\n",
       "       'Var143', 'Var144', 'Var149', 'Var153', 'Var160', 'Var163', 'Var173',\n",
       "       'Var181', 'Var194', 'Var200', 'Var201', 'Var206', 'Var214', 'Var217',\n",
       "       'Var218', 'Var225', 'Var229', 'Var57', 'Var73', 'Var113', 'Var193',\n",
       "       'Var195', 'Var196', 'Var198', 'Var204', 'Var207', 'Var210', 'Var211',\n",
       "       'Var212', 'Var216', 'Var220', 'Var221', 'Var222', 'Var226', 'Var227',\n",
       "       'Var228', 'appetency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep any variable that is missing LESS than 80% of their Negative observations \n",
    "#      AND \n",
    "# The difference between the missing value percentage for Positive vs. Negative is more than 1%\n",
    "# \n",
    "# In other words, they need to be mostly missing AND missing at roughly the same breakdown\n",
    "\n",
    "keepVars = allMiss.loc[(allMiss['NegMissPerc'] < 0.8) & (abs(allMiss['PosNegDiff']) > 0.01)] \n",
    "\n",
    "# Also, any variable with no missing values\n",
    "keepVars2 = allMiss.loc[(allMiss['NegMissPerc'] == 0)] \n",
    "\n",
    "# & abs(allMiss['PosNegDiff']) < 0.01]\n",
    "len(keepVars2)\n",
    "keepVars2.head\n",
    "\n",
    "keepVarsAll = pd.concat([keepVars, keepVars2], axis = 0)\n",
    "\n",
    "\n",
    "df3 = df2[keepVarsAll.index]\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f8c62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Var6', 'Var7', 'Var13', 'Var21', 'Var22', 'Var24', 'Var25', 'Var28',\n",
      "       'Var35', 'Var38', 'Var44', 'Var65', 'Var72', 'Var74', 'Var76', 'Var78',\n",
      "       'Var81', 'Var83', 'Var85', 'Var94', 'Var109', 'Var112', 'Var119',\n",
      "       'Var123', 'Var125', 'Var126', 'Var132', 'Var133', 'Var134', 'Var140',\n",
      "       'Var143', 'Var144', 'Var149', 'Var153', 'Var160', 'Var163', 'Var173',\n",
      "       'Var181', 'Var194', 'Var201', 'Var218', 'Var225', 'Var229', 'Var57',\n",
      "       'Var73', 'Var113', 'Var196', 'Var210', 'Var211', 'Var221', 'Var227',\n",
      "       'appetency'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Last thing for cleaning (famous last words) - drop any categoricals with more than 20-30 values\n",
    "# Those are likely names or street addresses or something else useless \n",
    "\n",
    "# We know that Vars 190-230 are categorical - let's see how many of them have more than 20 values\n",
    "for varNum in range(191,231):\n",
    "    varName = 'Var' + str(varNum)\n",
    "    \n",
    "    if (varName in df3.columns):\n",
    "        if (len(df3['Var' + str(varNum)].unique()) > 10):\n",
    "            print('Var' + str(varNum), len(df['Var' + str(varNum)].unique()))\n",
    "            del df3[varName]\n",
    "    #     print(df2.groupby(['appetency','Var' + str(varNum)])['Var' + str(varNum)].count())\n",
    "    # print()\n",
    "    # print('Var' + str(varNum), df['Var' + str(varNum)].unique())\n",
    "    \n",
    "print(df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ded49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.reset_index()\n",
    "numCols = df4.shape[1]\n",
    "df4['MissingValuesByRow'] =  df4.apply(lambda x: numCols - x.count(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59bfea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     13002\n",
       "2      6591\n",
       "3      5492\n",
       "6      5325\n",
       "41     4279\n",
       "5      4145\n",
       "0      3677\n",
       "1      3259\n",
       "7      1362\n",
       "9       771\n",
       "42      718\n",
       "12      362\n",
       "14      337\n",
       "10      246\n",
       "8       217\n",
       "13       93\n",
       "15       53\n",
       "11       48\n",
       "43       12\n",
       "16       10\n",
       "18        1\n",
       "Name: MissingValuesByRow, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['MissingValuesByRow'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28963fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Var6', 'Var7', 'Var13', 'Var21', 'Var22', 'Var24', 'Var25',\n",
       "       'Var28', 'Var35', 'Var38', 'Var44', 'Var65', 'Var72', 'Var74', 'Var76',\n",
       "       'Var78', 'Var81', 'Var83', 'Var85', 'Var94', 'Var109', 'Var112',\n",
       "       'Var119', 'Var123', 'Var125', 'Var126', 'Var132', 'Var133', 'Var134',\n",
       "       'Var140', 'Var143', 'Var144', 'Var149', 'Var153', 'Var160', 'Var163',\n",
       "       'Var173', 'Var181', 'Var194', 'Var201', 'Var218', 'Var225', 'Var229',\n",
       "       'Var57', 'Var73', 'Var113', 'Var196', 'Var210', 'Var211', 'Var221',\n",
       "       'Var227', 'appetency'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any row that is missing more than half of the columns \n",
    "df5 = df4.loc[df4['MissingValuesByRow'] < (numCols/2),]\n",
    "\n",
    "\n",
    "df6 = df5.drop(['MissingValuesByRow'], axis = 1)\n",
    "df6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90e3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('orange_small_train trimmed v4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50c387",
   "metadata": {},
   "source": [
    "### Pandas Profiling Report\n",
    "\n",
    "https://pandas-profiling.ydata.ai/docs/master/rtd/pages/advanced_usage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb7d8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f21012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c5e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install markupsafe --upgrade\n",
    "# ! pip install markupsafe==2.0.1 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf275332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b07ce3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9c749ae9c701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m profile = train_X.profile_report(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Report without correlations\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcorrelations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "# pandas_profiling.ProfileReport(df3)\n",
    "\n",
    "# profile = df2.profile_report(\n",
    "#     title=\"Report without correlations\",\n",
    "#     correlations=None,\n",
    "#     interactions = {\n",
    "#         \"continuous\":False,\n",
    "#         \"targets\": {'appetency'}\n",
    "#     },\n",
    "# )\n",
    "\n",
    "profile = train_X.profile_report(\n",
    "    title=\"Report without correlations\",\n",
    "    correlations=None,\n",
    "    interactions = {\n",
    "        \"continuous\":False,\n",
    "    },\n",
    ")\n",
    "\n",
    "profile.to_file(\"output - trimmed vars train X v2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b49e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
